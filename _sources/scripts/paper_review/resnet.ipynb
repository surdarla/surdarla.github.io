{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet\n",
    "\n",
    "Deep Residual Learning from Image Recognition\n",
    "\n",
    "{bdg-link-primary}`Paper PDF<https://arxiv.org/pdf/1512.03385>`\n",
    "\n",
    "```{admonition} Abstract\n",
    ":class: dropdown, note\n",
    "\n",
    "Deeper neural networks are more difficult to train. We present **a residual learning framework** to ease the training of networks that are substantially deeper than those used previously(vgg). We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8Ã—deeper than VGG nets [41] but still having *lower complexity*. An ensemble of these residual nets achieves *3.57% error on the ImageNet* testset. This result won the 1st place on theILSVRC 2015 classification task.  We also present analysis on CIFAR-10 with 100 and 1000 layers.The depth  of representations  is  of  central  importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement  on  the  COCO  object  detection  dataset. Deep residual nets are foundations of our submissions to ILSVRC& COCO 2015 competitions 1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.\n",
    "```\n",
    "\n",
    "Deep Residual Learning for Image Recognition ì´ë€ ì œëª©ì˜ ë…¼ë¬¸ìœ¼ë¡œ ìš°ë¦¬ê°€ ë§ì´ ë“¤ì–´ë³¸ 'resnet'ì— ëŒ€í•´ ë‚˜ì˜¨ ë…¼ë¬¸ì´ë‹¤. 2014ë…„ì— vggë…¼ë¬¸ì´ ë‚˜ì˜¤ê³  ë°”ë¡œ ë‹¤ìŒ í•´ì— ë‚˜ì˜¨ ë…¼ë¬¸ìœ¼ë¡œ, ì‚¬ì‹¤ìƒ vggì˜ êµ¬ì¡°ì— residual mappingì´ë¼ëŠ” ì•„ì´ë””ì–´ë§Œì„ ì¶”ê°€í•˜ê³ ë„ imagenet classificationì—ì„œ ëˆˆì— ë„ëŠ” ì ìˆ˜ í–¥ìƒì„ ë³´ì˜€ë‹¤. resnetì´ë¼ëŠ” ë…¼ë¬¸ì€ *ì•„ì´ë””ì–´ ìì²´ê°€ ì‰½ë‹¤*ëŠ” ì , ê·¸ë¦¬ê³  ê·¸ ì•„ì´ë””ì–´ê°€ ë‹¹ì‹œì˜ ëª¨ë¸ì˜ ê¹Šì´ì™€ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì„ í˜•ì ì¸ ìƒê´€ê´€ê³„ë¥¼ ì´ë£¨ì§€ ëª»í•˜ëŠ” *ë¬¸ì œ(degradation problem)ë¥¼ ì‰¬ìš´ ë…¼ë¦¬ë¡œ í•´ê²°í•œë‹¤ëŠ” ì *ì—ì„œ ì¢‹ì€ ë…¼ë¬¸ìœ¼ë¡œ ì§€ê¸ˆê¹Œì§€ í‰ê°€ëœë‹¤. ìš°ì„ ì€ resentì—ì„œ í•´ê²°í•˜ê³ ì í•˜ëŠ” ë¬¸ì œë¶€í„° ì‚´í´ë³´ì.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¬¸ì œ ì„¤ì • problem set-up\n",
    "\n",
    "vggë¥¼ í†µí•´ì„œ image classificationì´ë¼ëŠ” ê³¼ì œì—ì„œ ë§ì€ breakthroughê°€ ìˆì—ˆë‹¤. cnn layerë¥¼ ê¹Šì´ ìŒ“ìŒìœ¼ë¡œì¨ low/mid/high ìˆ˜ì¤€ì˜ featureë“¤ì„ í†µí•©í•˜ê³ , ë” ê¹Šì´ ìŒ“ì„ìˆ˜ë¡ ë” ë§ì€ featureë“¤ì„ dataì—ì„œ ì¶”ì¶œí•  ìˆ˜ ìˆê²Œ ëœ ê²ƒì´ë‹¤. í•˜ì§€ë§Œ ë¬´ì¡°ê±´ ê¹Šì´ë¥¼ ë§ì´ ìŒ“ëŠ”ë‹¤ê³  ë˜ì—ˆë˜ ê²ƒì€ ì•„ë‹ˆë‹¤. ë°‘ì˜ 2ê°œì˜ ë¬¸ì œê°€ ê·¸ê²ƒì´ë‹¤.\n",
    "\n",
    "### 1. vanishing/exploding gradients problem\n",
    "\n",
    "```{epigraph}\n",
    "Is learning better networks as easy as stacking more layers?\n",
    "\n",
    "-- bro. of course not!\n",
    "```\n",
    "\n",
    "ì²«ë²ˆì§¸ ë¬¸ì œëŠ” gradientê°€ ì†Œì‹¤ë˜ê±°ë‚˜ í­ë°œí•´ë²„ë¦¬ëŠ” ë¬¸ì œë‹¤. layerê°€ ëª‡ ì¸µ ë˜ì§€ ì•ŠëŠ” shallowí•œ networkì—ì„œëŠ” ì´ëŸ¬í•œ ë¬¸ì œê°€ ë‚˜íƒ€ë‚˜ì§€ ì•Šê±°ë‚˜ ê±±ì •ì´ í•„ìš”ì—†ì„ ì •ë„ ì´ì§€ë§Œ, networkê°€ ê¹Šì–´ì§€ë©´ gradient(ê²½ì‚¬ë„)ê°€ `too small or big for training to work effectively`í•˜ê²Œ ë˜ê³  ì´ ë¬¸ì œê°€ vanishing exploding gradient ë¬¸ì œë‹¤. [sigmoid](sigmoid) í•¨ìˆ˜ë¥¼ ìƒê°í•˜ë©´ ë¬¸ì œì— ëŒ€í•´ ì´ì• í•˜ê¸° ì‰½ë‹¤. \n",
    "\n",
    "> when n hidden layers use an activation like the sigmoid function, n small derivatives are multiplied together. Thus, the gradient decreases exponentially as we propagate down to the initial layers. \n",
    "\n",
    "chain ruleì— ë”°ë¼ ê° layerìƒì—ì„œì˜ derivativeëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ ë”°ë¼ì„œ ê³±í•´ì§€ê³ , ë°©í–¥ì„±ì€ ëë‹¨ì—ì„œ ë§¨ ì²˜ìŒ layerë¡œ í–¥í•˜ê²Œ ëœë‹¤. ë’¤ì—ì„œë¶€í„° ì•ìœ¼ë¡œ í–¥í•˜ëŠ” back propagationì—ì„œ sigmoidë¥¼ non-linear activaiton functionìœ¼ë¡œ ì‚¬ìš©í•˜ë©´, ìŒì˜ xê°’(input)ë“¤ì€ ì „ë¶€ 0ì— í•œì—†ì´ ê°€ê¹Œì›Œì§€ê¸° ë•Œë¬¸ì— í™œì„±í™”ê°€ ì˜ë˜ì§€ ì•Šê³ , ê³±ì…ˆì´ ì§„í–‰ë¨ì— ë”°ë¼ ì•„ì£¼ì•„ì£¼ ì‘ì•„ì§€ê²Œëœë‹¤. ì´ëŠ” ê³§ ë§¨ ì•ê¹Œì§€ ì˜¤ë©´ gradientê°€ ì‚¬ë¼ì§„ ê²ƒ ì²˜ëŸ¼, ê·¸ë¦¬ê³  í™œì„±í™” ì—­í• ì„ ì œëŒ€ë¡œ í•˜ì§€ ëª»í•˜ëŠ” íš¨ê³¼ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. \n",
    "\n",
    "í•˜ì§€ë§Œ ì´ëŸ¬í•œ ë¬¸ì œëŠ” ë…¼ë¬¸ìƒì—ì„œëŠ” ë§ì´ í•´ê²°ë˜ì—ˆë‹¤ê³  ë§í•œë‹¤. í•™ìŠµ ìì²´ê°€ ì•ˆë˜ëŠ” ë¬¸ì œì´ê³  gradientë¥¼ ì‚´ë¦¬ëŠ” ê²ƒì´ ë¬¸ì œì„ìœ¼ë¡œ nomarlized initialization, intermediate normalization layers ì´ ë‘ ë°©ë²•ì—ì„œ í•´ê²°ë˜ì—ˆë‹¤ê³  ë³¸ë‹¤. ë…¼ë¬¸ì—ì„œ ì£¼ë¡œ ë‹¤ë£¨ê³ ìí•˜ê³  í•´ê²°í•˜ê³  ì‹¶ì€ ë¬¸ì œëŠ” 2ë²ˆì¨° ë¬¸ì œì´ë‹¤.\n",
    "\n",
    "### 2. Degradation problem \n",
    "\n",
    "ê¹Šì€ networkì´ ìˆ˜ë ´ì„ ì‹œì‘í•œë‹¤ê³ í•´ë„, degradation problem(ì„±ëŠ¥ ì €í•˜ ë¬¸ì œ)ê°€ ë‚˜íƒ€ë‚  ìˆ˜ ìˆë‹¤ê³  ë§í•œë‹¤. ì´ ë¬¸ì œëŠ”  gradient vanishing/exploding ë¬¸ì œë³´ë‹¤ ì¢€ ë” ë„“ì€ ë²”ìœ„ì˜ ë¬¸ì œì´ë‹¤. ì´ ë¬¸ì œì˜ ìƒí™©ì—ì„œ networkëŠ” í•™ìŠµë„ ë˜ê³ , gradientë„ ì‚´ì•„ìˆê³ , accuracy scoreê°€ ìƒìŠ¹ì€ í•˜ëŠ”ë°, ì˜¤íˆë ¤ depthê°€ ë‚®ì€ networkë³´ë‹¤ depthë¥¼ ë†’ì¸ networkê°€ ì •í™•ë„ ë“±ì˜ í‰ê°€ì§€í‘œì—ì„œ ë” ë†’ì•„ì•¼ í•˜ëŠ”ë° ê·¸ë ‡ì§€ ëª»í•˜ëŠ” í˜„ìƒì„ ë§í•œë‹¤. \n",
    "\n",
    "```{figure} ../../images/resnet_1.png\n",
    "---\n",
    "height: 300px\n",
    "name: resnet-fig1\n",
    "---\n",
    "56 layer networkê°€ 20 layer networkë³´ë‹¤ errorìœ¨ì´ ë†’ì€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì„±ëŠ¥ì´ ë” ì˜ ì•ˆë‚˜ì˜¨ ê²ƒì´ë‹¤.\n",
    "```\n",
    "\n",
    "deeper is betterë¥¼ í•˜ë‚˜ì˜ ìš”ì†Œë§Œ ë„£ìœ¼ë©´ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ê²ƒ, ì¦‰ degradation problemì„ í•´ê²°í•˜ëŠ” ê²ƒ - ì´ ë…¼ë¬¸ì—ì„œëŠ” `Redisual mapping`ì´ë‹¤."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual mapping, Identity mapping\n",
    "\n",
    "```{margin} identity mapping?\n",
    "\n",
    "inputê³¼ outputì„ í¬í•¨í•˜ëŠ” í•¨ìˆ˜ë¼ê³  ìƒê°í•˜ë©´ ëœë‹¤.\n",
    "\n",
    "í•œ ì˜ì—­ì˜ ìš”ì†Œë¥¼ ë‹¤ë¥¸ ì˜ì—­ì˜ ìš”ì†Œì™€ ì—°ê²°í•˜ëŠ” ê³¼ì • í˜¹ì€ í•¨ìˆ˜ì´ë‹¤. y = f(x) ë¼ëŠ” ì‹ì„ ë³¸ë‹¤ë©´ x inputì„ yë¡œ ë°”ê¾¸ëŠ” í•¨ìˆ˜ ìì²´ê°€ mappingì´ë¼ê³  í•  ìˆ˜ ìˆê³ , x(input)ëŠ” f(function)ë¼ëŠ” mapping, í•¨ìˆ˜ë¥¼ í†µê³¼í•¨ìœ¼ë¡œì¨ y(output)ê°€ ëœë‹¤. \n",
    "\n",
    "image classification ì—ì„œëŠ” input(ì´ë¯¸ì§€) $\\to$ label(number) ìì²´ê°€ í•˜ë‚˜ì˜ mappingì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤. ì´ëŸ° ëŒ€ì‘ê´€ê³„ë¥¼ mappingì´ë¼ê³  ë³´ë©´ ëœë‹¤. ì¼ë°˜ì ì¸ ìˆ˜í•™ì—ì„œëŠ” í•˜ë‚˜ì˜ í•¨ìˆ˜ê°€ mapping functionìœ¼ë¡œ ë³¼ ìˆ˜ ìˆê³ , ë”¥ëŸ¬ë‹ì—ì„œëŠ” í¬ê²Œë³´ë©´ ëª¨ë¸ì´ mapping functionì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤. ë‹¤ë§Œ ì¢€ ë³µì¡í•œ non-linear mapping functionì´ë¼ê³  ë³¼ ìˆ˜ ìˆê² ë‹¤. ë”¥ëŸ¬ë‹ì—ì„œëŠ” ì•„í‚¤í…ì³, ê°€ì¤‘ì¹˜, í™œì„±í™” í•¨ìˆ˜ ë“±ì— ì˜í•´ ê²°ì •ëœë‹¤. ë˜í•œ ì ì ˆí•œ outputì„ ìœ„í•´ ìµœì í™” ê³¼ì •ì´ í•„ìš”í•˜ë‹¤.\n",
    "\n",
    "ê·¸ë ‡ë‹¤ë©´ identity mapping(í•­ë“± ë§¤í•‘)ì€ ë¬´ì—‡ì¼ê¹Œ? í•­ë“±ë§¤í•‘ ê·¸ëŸ¬ë‹ˆê¹ ìˆ˜í•™ì ìœ¼ë¡œ í‘œí˜„í•˜ë©´ $y=f(\\text{x})=\\text{x}$ì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤. \n",
    "```\n",
    "\n",
    "```{figure} ../../images/resnet_2.png\n",
    "---\n",
    "height: 300px\n",
    "name: resnet-fig2\n",
    "---\n",
    "obsidianìœ¼ë¡œ ë‚´ë§˜ëŒ€ë¡œ ê·¸ë ¤ë³¸ fig2\n",
    "```\n",
    "\n",
    "ê¸°ì¡´ì˜ vggì—ì„œì˜ mapping blockì„ $H(\\text{x})$ì´ë¼ê³  í•œë‹¤ë©´, ì´ëŸ° blockì´ 18ê°œì •ë„ ì´ì–´ì ¸ ë¶™ì–´ìˆëŠ” í˜•íƒœì˜€ë‹¤. block ë‚´ë¶€ì—ëŠ” cnn layer + relu layer + cnn layer + relu layer ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. \n",
    "\n",
    "resentì—ì„œëŠ” ì´ëŸ¬í•œ êµ¬ì¡°ì—ì„œ blockë§ˆë‹¤ì˜ input(x) $\\to$ output($H(\\text{x})$=y) ê´€ê³„ë¥¼ ë¶„í•´í•œë‹¤. input(x) + residual(F(x)) $\\to$ output($H(\\text{x})$=y). ê²°êµ­ í•˜ë‚˜ì˜ ë¸”ëŸ­ ìƒì—ì„œ í•™ìŠµí•´ì•¼í•˜ëŠ” ë¶€ë¶„ì€ $H(\\text{x}) - x = F(\\text{x})$ê°€ ë˜ëŠ” ê²ƒì´ê³  ì´ê²ƒì´ `Residual`ì´ ë˜ëŠ” ê²ƒì´ë‹¤. ê·¸ë¦¬ê³  inputì€ y=f(x)=x ì²˜ëŸ¼ inputê°’ì´ outputê³¼ ê°™ì€ ê²ƒ ì²˜ëŸ¼ mappingë˜ëŠ” ë¶€ë¶„ì„ìœ¼ë¡œ identity mappingì´ë¼ê³  ë¶ˆë¦°ë‹¤. \n",
    "\n",
    "$$\n",
    "\\begin{gather}\n",
    "\\tag{residual mapping in fig2}F = W_2\\sigma(W_1 x)\\\\\n",
    "\\tag{a building block} \\text{y} = W_2\\sigma(W_1\\text{x}) + x\\\\\n",
    "\\tag{Equ 1}\\text{y} = F(\\text{x},\\{ W_i \\}) + \\text{x} \\\\\n",
    "\\tag{Equ 2} \\text{y} = F(\\text{x},\\{ W_i \\}) + W_s\\text{x}\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "- F : residual function\n",
    "- ë§Œì•½ Fê°€ single layerë¼ë©´ : y = W_1 x + x ê°€ ë  ìˆ˜ë„ ìˆë‹¤.\n",
    "- F(x, {W_i})ëŠ” multiple convolutional layersë¥¼ í‘œí˜„\n",
    "\n",
    "\n",
    "ê¸°ì¡´ì˜ outputì—ë‹¤ inputì„ ë”í•´ì£¼ëŠ” `+`ì˜ ê°œë…ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ë„ ìˆê³ , ê¸°ì¡´ì˜ mappingì„ í•´ì²´í•˜ëŠ” `-`ì˜ ê°œë…ìœ¼ë¡œ ìƒê°í•´ë³¼ ìˆ˜ ë„ ìˆë‹¤. `-`ì˜ ê°œë…ìœ¼ë¡œ ì ‘ê·¼í•œë‹¤ë©´ ê¸°ì¡´ì— optimize í•´ ì£¼ì–´ì•¼í•  ë¶€ë¶„ì´ ì¤„ì–´ë“ ë‹¤ëŠ” ê´€ì ìœ¼ë¡œ ì ‘ê·¼í•  ìˆ˜ ìˆì„ ê²ƒì´ê³ , ì´ê²ƒì´ ë…¼ë¬¸ì—ì„œ ê°€ì •í•˜ê³  ì ‘ê·¼í•œ ì§€ì ì´ë‹¤. identity mapping(x)ê°€ ì´ë¯¸ optimalí•˜ê²Œ mappingì„ ì§„í–‰í•´ì™”ë‹¤ë©´ ë‚¨ì€ residual mapping(F(x))ë§Œ 0ì— ê°€ê¹ê²Œ ë§Œë“¤ë©´ ëœë‹¤ëŠ” ê²ƒì´ë‹¤. ê·¸ëŸ¼ H(x)ê°€ ê²°ê³¼ì ìœ¼ë¡œ optimalí•´ì§ˆ ê²ƒì´ê³  outputì€ xë¡œ ë˜ì–´ì„œ ë‹¤ìŒ blockì˜ inputì´ ë  ê²ƒì´ë‹¤.\n",
    "\n",
    "> The  degradation  problem  suggests  that  the  solvers might have difficulties in approximating identity mappingsby multiple nonlinear layers. \n",
    "\n",
    "ì—¬ê¸°ì„œ solverë€ optimization algorithm, back-propagation algorithmì„ ë§í•œë‹¤. gradientë¥¼ ê³„ì‚°í•˜ì—¬ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ì—¬ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê³¼ì •ì„ ë§í•œë‹¤. ì¦‰ ê¸°ì¡´ì˜ identity mappingì´ ì—†ë˜ networkì—ì„œì˜ ìµœì í™” ê³¼ì •ì—ì„œì˜ degradation problemì€ ë¹„ì„ í˜• ë ˆì´ì–´ë¥¼ ì—¬ëŸ¬ ê°œ í†µê³¼í•˜ë©´ì„œ ì…ë ¥ê³¼ ì¶œë ¥ì´ ê°™ì€(identity mapping)ì˜ ê²½ìš°ì— ëŒ€í•œ ëŒ€ì²˜ê°€ ì–´ë ¤ì›Œ ì§„ë‹¤ëŠ” ê²ƒì´ë‹¤. ê·¸ë¦¬ê³  ìœ„ì˜ residual mappingê³¼ identity mappingì„ shortcut connectionìœ¼ë¡œ êµ¬í˜„í•¨ìœ¼ë¡œì¨ ê¹Šì–´ì§€ëŠ” networkì—ì„œì˜ gradient íë¦„ì„ ë³´ì¡´í•  ìˆ˜ ìˆì—ˆë‹¤ê³  ë§í•œë‹¤.\n",
    "\n",
    "ë¬¼ë¡  identity mappingì´ optimalí•  ê²½ìš°ëŠ” ì‹¤ì œ í•™ìŠµê³¼ì •ì—ì„œëŠ” ì´ë£¨ì–´ ì§€ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤ê³  ë§ë‹¤. í•˜ì§€ë§Œ ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  ê¸°ì¡´ì˜ inputê°’ì„ ì°¸ì¡°í•˜ëŠ” ê²ƒ ë§Œìœ¼ë¡œë„ í•™ìŠµì— ë„ì›€ì´ ëœë‹¤ê³  ë…¼ë¬¸ì—ì„œëŠ” ë§í•œë‹¤. ë‹¤ìŒ ë¸”ë¡ì˜ residual mappingì´ ì´ì „ ë¸”ë¡ì˜ identity mappingì„ ì°¸ì¡°í•˜ëŠ” ê²ƒ ë§Œìœ¼ë¡œë„ í•™ìŠµì˜ ìš”ë™(?)ì´ ì ì–´ì§„ë‹¤ê³  ë§í•œë‹¤."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shortcut connection == identity mapping?\n",
    "\n",
    "shortcut connectionì€ ì…ë ¥ê°’ì„ ë’¤ë¡œ ë„˜ê²¨ì„œ ë”í•´ì¤€ë‹¤. ì´ê²ƒì—ë„ ì¢…ë¥˜ê°€ ìˆê³  identity mappingì€ 1ë²ˆìœ¼ë¡œ ê·¸ ì¢…ë¥˜ì¤‘ì— í•˜ë‚˜ë¡œ ë³¼ ìˆ˜ ìˆìŒìœ¼ë¡œ ì •í™•íˆëŠ” ì°¨ì´ê°€ ì¡´ì¬í•œë‹¤. inputê³¼ outputì˜ dimensionì´ ë‹¬ë¼ì§€ë©´ ê³ ë ¤í•´ì•¼í•  ê²ƒì´ ë§ì•„ì§„ë‹¤. \n",
    "\n",
    "1. Identity Shortcut Connection (í•µì‹¬): Identity Shortcut Connectionì€ ì´ì „ ë ˆì´ì–´ì˜ ì¶œë ¥ì„ í˜„ì¬ ë ˆì´ì–´ì˜ ì…ë ¥ì— ì§ì ‘ ë”í•´ì£¼ëŠ” ë°©ì‹ì…. \n",
    "2. Projection Shortcut Connection: Projection Shortcut Connectionì€ ì´ì „ ë ˆì´ì–´ì˜ ì¶œë ¥ì„ í˜„ì¬ ë ˆì´ì–´ì˜ ì…ë ¥ì— ì„ í˜• ë³€í™˜(projection)í•˜ì—¬ í¬ê¸°ë‚˜ ì°¨ì›ì„ ë§ì¶˜ í›„ ë”í•´ì£¼ëŠ” ë°©ì‹. ì´ëŠ” ì°¨ì›ì´ ë‹¤ë¥¸ ê²½ìš°ì— ì‚¬ìš©ë˜ë©°, ì„ í˜• ë³€í™˜ì„ í†µí•´ ì°¨ì› ì¼ì¹˜ë¥¼ ìœ ì§€í•˜ê³  ê·¸ë˜ë””ì–¸íŠ¸ íë¦„ì„ ë³´ì¡´í•  ìˆ˜ ìˆë‹¤.\n",
    "3. Dimension Matching Shortcut Connection: Dimension Matching Shortcut Connectionì€ ì´ì „ ë ˆì´ì–´ì˜ ì¶œë ¥ê³¼ í˜„ì¬ ë ˆì´ì–´ì˜ ì…ë ¥ì˜ ì°¨ì›ì´ ë‹¤ë¥¼ ê²½ìš°, ì°¨ì›ì„ ë§ì¶”ê¸° ìœ„í•´ ì¶”ê°€ì ì¸ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ì‹. ì´ëŠ” ì°¨ì›ì´ ë‹¤ë¥¸ ê²½ìš°ì— ì‚¬ìš©ë˜ë©°, ì°¨ì›ì„ ì¼ì¹˜ì‹œì¼œ ê·¸ë˜ë””ì–¸íŠ¸ íë¦„ì„ ë³´ì¡´í•˜ê³  ì •ë³´ì˜ ì†ì‹¤ì„ ìµœì†Œí™”.\n",
    "4. Skip Connection: Skip Connectionì€ ì´ì „ ë ˆì´ì–´ì˜ ì¶œë ¥ì„ í˜„ì¬ ë ˆì´ì–´ì˜ ì…ë ¥ìœ¼ë¡œ ë°”ë¡œ ì „ë‹¬í•˜ëŠ” ë°©ì‹. Identity Shortcut Connectionì€ Skip Connectionì˜ í•œ ì¢…ë¥˜ë¡œ ë³¼ ìˆ˜ ìˆë‹¤. Skip Connectionì€ ë„¤íŠ¸ì›Œí¬ì˜ ì—¬ëŸ¬ ë ˆì´ì–´ë¥¼ ê±´ë„ˆë›°ì–´ ê·¸ë˜ë””ì–¸íŠ¸ íë¦„ì„ ë” ì§§ê²Œ ë§Œë“¤ì–´ ì¤Œìœ¼ë¡œì¨ ê·¸ë˜ë””ì–¸íŠ¸ ì†Œì‹¤ ë¬¸ì œë¥¼ ì™„í™”ì‹œí‚¤ê³ , ì •ë³´ì˜ ì†ì‹¤ì„ ì¤„ì¼ ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "ì´ì „ì˜ ì—°êµ¬ë“¤ì—ì„œ shortcut connectionì€ 'highway networks'ì—ì„œ gating functionìœ¼ë¡œ ì´ìš©ë˜ì—ˆë‹¤ê³  í•œë‹¤. ì´ gatesë“¤ì€ data-dependentí•˜ê³  parameterê°€ ìˆì—ˆìœ¼ë©° ë‹«í ìˆ˜ ìˆì—ˆë‹¤ê³  í•œë‹¤. í•˜ì§€ë§Œ resnetì—ì„œì˜ shortcut connectionì€ `parameter-free, never closed`ë¼ê³  í•œë‹¤.\n",
    "\n",
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py\n",
    "from functools import partial\n",
    "from typing import Any, Callable, List, Optional, Type, Union\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes: int,\n",
    "            out_planes: int,\n",
    "            stride: int = 1,\n",
    "            groups:int = 1,\n",
    "            dilation: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes,\n",
    "                     kernel_size=3,\n",
    "                     stride=stride,\n",
    "                     padding=dilation,\n",
    "                     groups=groups,\n",
    "                     bias=False,\n",
    "                     dilation=dilation,\n",
    "                     )\n",
    "\n",
    "def conv1x1(in_planes: int,\n",
    "            out_planes: int,\n",
    "            stride: int = 1,) -> nn.Conv2d:\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "        expansion: int = 1\n",
    "        \n",
    "        def __init__(\n",
    "                self,\n",
    "                inplanes: int,\n",
    "                planes: int,\n",
    "                stride: int = 1,\n",
    "                downsample: Optional[nn.Module] = None,\n",
    "                groups: int = 1,\n",
    "                base_width: int = 64,\n",
    "                dilation: int = 1,\n",
    "                norm_layer: Optional[Callable[...,nn.Module]] = None,\n",
    "        ) -> None:\n",
    "                super().__init__()\n",
    "                if norm_layer is None:\n",
    "                        norm_layer = nn.BatchNorm2d\n",
    "                if groups != 1 or base_width != 64:\n",
    "                        raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n",
    "                if dilation > 1:\n",
    "                        raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "                # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "                self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "                self.bn1 = norm_layer(planes)\n",
    "                self.relu = nn.ReLU(inplace=True)\n",
    "                self.conv2 = conv3x3(planes, planes)\n",
    "                self.bn2 = norm_layer(planes)\n",
    "                self.downsample = downsample\n",
    "                self.stride = stride\n",
    "                \n",
    "        def forward(self, x: Tensor) -> Tensor:\n",
    "                identity = x\n",
    "                \n",
    "                out = self.conv1(x)\n",
    "                out = self.bn1(out)\n",
    "                out = self.relu(out)\n",
    "                \n",
    "                out = self.conv2(out)\n",
    "                out = self.bn2(out)\n",
    "                # residual function\n",
    "                \n",
    "                if self.downsample is not None:\n",
    "                        identity = self.downsample(x)\n",
    "                        \n",
    "                out += identity # identity mapping\n",
    "                out = self.relu(out)\n",
    "                return out\n",
    "                "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "```{figure} ../../images/resnet_3.png\n",
    "---\n",
    "height: 700px\n",
    "name: resnet-fig3\n",
    "---\n",
    "vgg19(19.6B FLOPs) - plain 34 layers(3.6B FLOPs) - with shortcut 34 layers(3.6B FLOPs). dotted lineì´ dimensionì´ ëŠ˜ì–´ë‚˜ëŠ” ë¶€ë¶„ì´ê³  ì´ ë¶€ë¶„ì€ equ2 $W_s$ 1x1 convolutionsë¡œ ë§ì¶°ì£¼ì—ˆë‹¤ê³  í•œë‹¤.\n",
    "```\n",
    "\n",
    "in training\n",
    "- he image is resized with its shorter side ran-domly sampled in for scale augmentation.A 224Ã—224 crop is randomly sampled from an image or its horizontal flip, with the per-pixel mean subtracted.\n",
    "- standard color augmentation\n",
    "- conv $\\to$ Batch Normalization $\\to$ non-linear activation f\n",
    "  - plain ë„¤íŠ¸ì›Œí¬ì—ì„œë„ ì‚¬ìš©ë¨ìœ¼ë¡œì¨ ì‹¤í—˜ìì²´ê°€ gradient vanishing problem ë³´ë‹¤ëŠ” degradation problemì— ì§‘ì¤‘í•˜ë„ë¡ í•¨.\n",
    "  - ensures forward propagated signals to have non-zero variances.  \n",
    "  - ì…ë ¥ ë°ì´í„°ì˜ ë¶„ì‚°ì„ ì¡°ì •í•˜ì—¬ gradientì˜ í¬ê¸°ë¥¼ ì•ˆì •í™”í•˜ì—¬ gradient vanishing problemì„ ì™„í™”í•˜ë©°, ì‘ì€ ë³€í™”ì—ëŠ” ëœ ë¯¼ê°í•œ ê°•ê²…í•œ ëª¨ë¸ì„ ë§Œë“¤ê³ , ë¹ ë¥´ê²Œ ìˆ˜ë ´í•˜ë„ë¡ ë•ëŠ” ì—­í• ì„ í•œë‹¤.\n",
    "  - ë˜í•œ backward propagated gradients(ì—­ì „íŒŒëœ ì†ì‹¤í•¨ìˆ˜ ìµœì†Œí™” ê°€ì¤‘ì¹˜ ë¯¸ë¶„ê°’)ê°€ ê±´ê°•í•˜ê³  ì ì ˆí•œ í¬ê¸°ë¥¼ ìœ ì§€í•˜ëŠ” ë° ë„ì›€ëœë‹¤.\n",
    "- weitght initialization\n",
    "- SGD with mini-batch 256 size\n",
    "- 0.1 lr with 10 error plateaus\n",
    "- 60 x 10^4 iter\n",
    "- 0.0001 weight decay, momentum 0.9\n",
    "- no dropout\n",
    "\n",
    "in testing\n",
    "- standard 10-crop testing\n",
    "- fully convolutional form\n",
    "- average scores at multiple scales{224,256,384,480,640}\n",
    "\n",
    "\n",
    "```{figure} ../../images/resnet_4.png\n",
    "---\n",
    "height: 400px\n",
    "name: resnet-fig4\n",
    "---\n",
    "\n",
    "```\n",
    "\n",
    "- (A) zero-padding shortcuts are usedfor increasing dimensions, and all shortcuts are parameter-free \n",
    "- (B)  projec-tion shortcuts are used for increasing dimensions, and othershortcuts are identity\n",
    "- (C) all shortcuts are projection\n",
    "\n",
    "ìœ„ì—ì„œ ë³´ì´ëŠ” ABCëŠ” shortcut connectionì„ ì–´ë–»ê²Œ êµ¬ì„±í–ˆëŠ”ì§€ê°€ ë‹¤ë¥´ê³ , cë¡œ ê°ˆìˆ˜ë¡ ì„±ëŠ¥ì€ ë‚˜ì•„ì¡Œì§€ë§Œ, Bë§Œìœ¼ë¡œë„ ìœ ì˜ë¯¸í•œ ë¬¸ì œ í•´ê²°ì„ ë³´ì„ìœ¼ë¡œ ëª¨ë“  shortcutì´ projection shortcutì´ ë  í•„ìš”ëŠ” ì—†ë‹¤ê³  ë§í•œë‹¤. í•´ë‹¹ ë…¼ë¬¸ ì´í›„ì— ë‚˜ì˜¨ fishnetì´ë¼ëŠ” ë…¼ë¬¸ì—ì„œëŠ” Cì˜ ë°©ì‹ì„ ì ê·¹ì±„ìš©í•´ì„œ resnetë³´ë‹¤ ì„±ëŠ¥ì„ ë†’ì˜€ë‹¤.\n",
    "\n",
    "\n",
    "### Deeper Bottleneck Architectures\n",
    "\n",
    "\n",
    "```{figure} ../../images/resnet_bottleneck.png\n",
    "---\n",
    "height: 400px\n",
    "name: resnet-fig5\n",
    "---\n",
    "Bottlenect desingn for deeper network architecture\n",
    "```\n",
    "\n",
    "```{figure} ../../images/resnet_50.png\n",
    "---\n",
    "height: 700px\n",
    "name: resnet-fig6\n",
    "---\n",
    "The architecture of ResNet-50-vd. (a) Stem block; (b) Stage1-Block1; (c) Stage1-Block2; (d) FC-Block.\n",
    "```\n",
    "\n",
    "18, 34 layersì—ì„œëŠ” 3x3,3x3ë¡œ 2ê°œì˜ conv layerë“¤ì„ ìŒ“ì•„ì„œ ë§Œë“¤ì—ˆì—ˆë‹¤ë©´, ë” ë‚˜ì•„ê°€ì„œ 50,101,152 layersë¥¼ ìœ„í•´ì„œ 1x1,3x3,1x1 ë¥¼ í•˜ë‚˜ì˜ ë¸”ë¡ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. ì´ê²ƒì„ bottleneck block ì´ë¼ê³  ë¶€ë¥¸ë‹¤. \n",
    "\n",
    "(linear projection conv)1x1 ì²«ë²ˆì§¸ filter layerëŠ” inputì˜ ì°¨ì›ì„ ì¤„ì´ê±°ë‚˜ ëŠ˜ë¦¬ëŠ”ë°(ì°¨ì›ì„ ë§ì¶”ëŠ”ë°) ì‚¬ìš©ëœë‹¤. ì´ë¥¼ í†µí•´ ê³„ì‚° ë¹„ìš©ì„ ì¤„ì´ê³ , ë” ì ì€ìˆ˜ì˜ í•„í„°ë¥¼ ì‚¬ìš©í•´ì„œ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•˜ë‹¤.ì´ ê³¼ì •ì—ì„œ ì¼ë¶€ ì •ë³´ì˜ ì†ì‹¤ì´ ë°œìƒí•  ìˆ˜ëŠ” ìˆë‹¤.\n",
    "\n",
    "ë‘ë²ˆì§¸ 3x3 filter layerëŠ” `bottleneck` ì—­í• ì„ ì‹¤ì§ˆì ìœ¼ë¡œ í•˜ëŠ” ê³µê°„ìœ¼ë¡œ ì°¨ì›ì´ ì¤„ì–´ë“ ë‹¤. ì°¨ì›ì´ ì¤„ì–´ë“ ë‹¤ëŠ” ê²ƒì€ feature íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ê²ƒì´ ì ì–´ì§„ë‹¤ëŠ” ê²ƒì´ë©°, ê°€ì¤‘ì¹˜ê°€ í° featureì— ì§‘ì¤‘í•˜ê²Œ ëœë‹¤. ì ì°¨ì ìœ¼ë¡œ output sizeê°€ 112x112 $\\to$ 56x56 $\\to$ 28x28 $\\to$ 14x14 $\\to$ 7x7 ë¡œ ì¤„ì–´ë“¤ë©´ì„œ cnnì˜ ê¸°ë³¸ì ì¸ ì—­í• (ê³µê°„ì ì¸ íŠ¹ì§• í•™ìŠµ)ì— ì¶©ì‹¤í•˜ê²Œ ëœë‹¤.\n",
    "\n",
    "ë§ˆì§€ë§‰ 1x1 filter layerëŠ” ì¤„ì–´ë“  ì°¨ì›ì„ ë‹¤ì‹œ ëŠ˜ë ¤ì£¼ë©´ì„œ ì°¨ì›ì„ ë³´ì¡´í•œë‹¤.\n",
    "\n",
    "resnet50ì˜ êµ¬ì¡°ë„ë¥¼ ì°¾ì€ ê²ƒì¸ë° ë…¼ë¬¸ì—ì„œëŠ” stageêµ¬ë¶„ì´ ì—†ì—ˆëŠ”ë° ì´ê²ƒì€ êµ¬ë¶„ì„ í•´ì„œ batch normë“±ì„ ë‹¤ë¥´ê²Œ ì‚¬ìš©í•˜ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ í‘œí˜„ë˜ê³  ìˆë‹¤.\n",
    "\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion: int = 4\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "        ) -> None:\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.0)) * groups\n",
    "        \n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "            \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        layers: List[int],\n",
    "        num_classes: int = 1000,\n",
    "        zero_init_residual: bool = False,\n",
    "        groups: int = 1,\n",
    "        width_per_group: int = 64,\n",
    "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        # _log_api_usage_once(self)\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\n",
    "                \"replace_stride_with_dilation should be None \"\n",
    "                f\"or a 3-element tuple, got {replace_stride_with_dilation}\"\n",
    "            )\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck) and m.bn3.weight is not None:\n",
    "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
    "                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:\n",
    "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
    "\n",
    "    def _make_layer(\n",
    "        self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        planes: int,\n",
    "        blocks: int,\n",
    "        stride: int = 1,\n",
    "        dilate: bool = False,\n",
    "    ) -> nn.Sequential:\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer\n",
    "            )\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(\n",
    "                block(\n",
    "                    self.inplanes,\n",
    "                    planes,\n",
    "                    groups=self.groups,\n",
    "                    base_width=self.base_width,\n",
    "                    dilation=self.dilation,\n",
    "                    norm_layer=norm_layer,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp= ResNet(BasicBlock, [2,2,2,2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [128, 1000]               --\n",
       "â”œâ”€Conv2d: 1-1                            [128, 64, 112, 112]       9,408\n",
       "â”œâ”€BatchNorm2d: 1-2                       [128, 64, 112, 112]       128\n",
       "â”œâ”€ReLU: 1-3                              [128, 64, 112, 112]       --\n",
       "â”œâ”€MaxPool2d: 1-4                         [128, 64, 56, 56]         --\n",
       "â”œâ”€Sequential: 1-5                        [128, 64, 56, 56]         --\n",
       "â”‚    â””â”€BasicBlock: 2-1                   [128, 64, 56, 56]         --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-1                  [128, 64, 56, 56]         36,864\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-2             [128, 64, 56, 56]         128\n",
       "â”‚    â”‚    â””â”€ReLU: 3-3                    [128, 64, 56, 56]         --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-4                  [128, 64, 56, 56]         36,864\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-5             [128, 64, 56, 56]         128\n",
       "â”‚    â”‚    â””â”€ReLU: 3-6                    [128, 64, 56, 56]         --\n",
       "â”‚    â””â”€BasicBlock: 2-2                   [128, 64, 56, 56]         --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-7                  [128, 64, 56, 56]         36,864\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-8             [128, 64, 56, 56]         128\n",
       "â”‚    â”‚    â””â”€ReLU: 3-9                    [128, 64, 56, 56]         --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-10                 [128, 64, 56, 56]         36,864\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-11            [128, 64, 56, 56]         128\n",
       "â”‚    â”‚    â””â”€ReLU: 3-12                   [128, 64, 56, 56]         --\n",
       "â”œâ”€Sequential: 1-6                        [128, 128, 28, 28]        --\n",
       "â”‚    â””â”€BasicBlock: 2-3                   [128, 128, 28, 28]        --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-13                 [128, 128, 28, 28]        73,728\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-14            [128, 128, 28, 28]        256\n",
       "â”‚    â”‚    â””â”€ReLU: 3-15                   [128, 128, 28, 28]        --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-16                 [128, 128, 28, 28]        147,456\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-17            [128, 128, 28, 28]        256\n",
       "â”‚    â”‚    â””â”€Sequential: 3-18             [128, 128, 28, 28]        8,448\n",
       "â”‚    â”‚    â””â”€ReLU: 3-19                   [128, 128, 28, 28]        --\n",
       "â”‚    â””â”€BasicBlock: 2-4                   [128, 128, 28, 28]        --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-20                 [128, 128, 28, 28]        147,456\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-21            [128, 128, 28, 28]        256\n",
       "â”‚    â”‚    â””â”€ReLU: 3-22                   [128, 128, 28, 28]        --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-23                 [128, 128, 28, 28]        147,456\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-24            [128, 128, 28, 28]        256\n",
       "â”‚    â”‚    â””â”€ReLU: 3-25                   [128, 128, 28, 28]        --\n",
       "â”œâ”€Sequential: 1-7                        [128, 256, 14, 14]        --\n",
       "â”‚    â””â”€BasicBlock: 2-5                   [128, 256, 14, 14]        --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-26                 [128, 256, 14, 14]        294,912\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-27            [128, 256, 14, 14]        512\n",
       "â”‚    â”‚    â””â”€ReLU: 3-28                   [128, 256, 14, 14]        --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-29                 [128, 256, 14, 14]        589,824\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-30            [128, 256, 14, 14]        512\n",
       "â”‚    â”‚    â””â”€Sequential: 3-31             [128, 256, 14, 14]        33,280\n",
       "â”‚    â”‚    â””â”€ReLU: 3-32                   [128, 256, 14, 14]        --\n",
       "â”‚    â””â”€BasicBlock: 2-6                   [128, 256, 14, 14]        --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-33                 [128, 256, 14, 14]        589,824\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-34            [128, 256, 14, 14]        512\n",
       "â”‚    â”‚    â””â”€ReLU: 3-35                   [128, 256, 14, 14]        --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-36                 [128, 256, 14, 14]        589,824\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-37            [128, 256, 14, 14]        512\n",
       "â”‚    â”‚    â””â”€ReLU: 3-38                   [128, 256, 14, 14]        --\n",
       "â”œâ”€Sequential: 1-8                        [128, 512, 7, 7]          --\n",
       "â”‚    â””â”€BasicBlock: 2-7                   [128, 512, 7, 7]          --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-39                 [128, 512, 7, 7]          1,179,648\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-40            [128, 512, 7, 7]          1,024\n",
       "â”‚    â”‚    â””â”€ReLU: 3-41                   [128, 512, 7, 7]          --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-42                 [128, 512, 7, 7]          2,359,296\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-43            [128, 512, 7, 7]          1,024\n",
       "â”‚    â”‚    â””â”€Sequential: 3-44             [128, 512, 7, 7]          132,096\n",
       "â”‚    â”‚    â””â”€ReLU: 3-45                   [128, 512, 7, 7]          --\n",
       "â”‚    â””â”€BasicBlock: 2-8                   [128, 512, 7, 7]          --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-46                 [128, 512, 7, 7]          2,359,296\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-47            [128, 512, 7, 7]          1,024\n",
       "â”‚    â”‚    â””â”€ReLU: 3-48                   [128, 512, 7, 7]          --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-49                 [128, 512, 7, 7]          2,359,296\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-50            [128, 512, 7, 7]          1,024\n",
       "â”‚    â”‚    â””â”€ReLU: 3-51                   [128, 512, 7, 7]          --\n",
       "â”œâ”€AdaptiveAvgPool2d: 1-9                 [128, 512, 1, 1]          --\n",
       "â”œâ”€Linear: 1-10                           [128, 1000]               513,000\n",
       "==========================================================================================\n",
       "Total params: 11,689,512\n",
       "Trainable params: 11,689,512\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 232.20\n",
       "==========================================================================================\n",
       "Input size (MB): 77.07\n",
       "Forward/backward pass size (MB): 5087.67\n",
       "Params size (MB): 46.76\n",
       "Estimated Total Size (MB): 5211.49\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(temp, input_size=(128,3,224,224))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchinfoëŠ” ìš”ì¦˜ì€ torchsummary, torchsummaryXê°€ updateë¥¼ í•˜ì§€ì•ŠëŠ” ìƒí™©ì—ì„œ ì¢‹ì€ ëŒ€ì•ˆì´ë‹¤. ë¬¼ë¡  í•„ìš” memoryë¥¼ ê³„ì‚°í•˜ëŠ”ë° ì‹œê°„ì´ ê½¤ë‚˜ ê±¸ë¦¬ëŠ” ê²ƒ ê°™ì§€ë§Œ, GPU ë©”ëª¨ë¦¬ë¥¼ ê³ ë ¤í•´ì„œ ì–¼ë§ˆë‚˜ì˜ batch sizeë¥¼ ë¯¸ë¦¬ ìƒê°í•´ë³´ëŠ”ë° ì¢‹ì€ toolë¡œ ë³´ì¸ë‹¤. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import torch.onnx\n",
    "# params = temp.state_dict()\n",
    "# dummy_data = torch.empty(1,3,224,224,dtype=torch.float32)\n",
    "# torch.onnx.export(temp, dummy_data,'onnx_test.onnx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../paper_review/onnx_test.svg\n",
    "onnxë¡œ ê·¸ë ¤ë³´ê³  svgë¡œ ì €ì¥í•œ resnet18.\n",
    "```\n",
    "\n",
    "ì—¬ê¸°ì„œ WëŠ” weightë¥¼ ë‚˜íƒ€ë‚´ê³  <feature x input channel x height x width> ìˆœìœ¼ë¡œ í‘œì‹œëœë‹¤. ê·¸ë¦¬ê³  BëŠ” biasì´ë‹¤."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "### ILSVRC'15\n",
    "\n",
    "```{figure} ../../images/resnet_imagenet.png\n",
    "---\n",
    "height: 300px\n",
    "name: resnet-fig7\n",
    "---\n",
    "\"ImageNet Large Scale Visual Recognition Challenge\" ILSVRCëŠ” 2010ë…„ë¶€í„° 2017ë…„ê¹Œì§€ ë§¤ë…„ ê°œìµœëœ ì´ë¯¸ì§€ ì¸ì‹ ëŒ€íšŒ\n",
    "```\n",
    "\n",
    "1. 2011 XRCE\n",
    "2. 2012 AlexNet(8 cnn 3 fc)\n",
    "3. 2013 ZFNet(alexnetë³´ë‹¤ ì¢€ë” ê¹Šê²Œ, ë” ì‘ì€ í•„í„°)\n",
    "4. 2014 GoogleNet(ì—¬ëŸ¬ í•„í„° ë³‘ë ¹ ì ìš© inception module) - VGG(ê°„ë‹¨ alex ë³´ë‹¤ deep)\n",
    "5. **2015 ResNet**\n",
    "6. 2016 GoogleNet-v4\n",
    "7. SENet(squeeze and excitation module channelê°„ì˜ ì˜ì¡´ì„± ê°•ì¡°)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "source - title\n",
    "\n",
    "- [Medium - Rohan #4: The vanishing gradient problem](https://ayearofai.com/rohan-4-the-vanishing-gradient-problem-ec68f76ffb9b)\n",
    "- [Medium - Understanding and visualizing ResNets](https://towardsdatascience.com/understanding-and-visualizing-resnets-442284831be8)\n",
    "- [DataScience - Neural networks: Deriving the sigmoid derivative via chain and quotient rules](https://hausetutorials.netlify.app/posts/2019-12-01-neural-networks-deriving-the-sigmoid-derivative/)\n",
    "- [ResearchGate - resnet 50 architecture](https://www.researchgate.net/figure/The-architecture-of-ResNet-50-vd-a-Stem-block-b-Stage1-Block1-c-Stage1-Block2_fig4_349646156)\n",
    "- [pytorch team - Resnet](https://pytorch.org/hub/pytorch_vision_resnet/)\n",
    "- [Jinsol Kim - Pytorchì˜ ì‹œê°í™” ë° í•™ìŠµ í˜„í™© í™•ì¸](https://gaussian37.github.io/dl-pytorch-observe/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{raw} html\n",
    "<script\n",
    "   type=\"text/javascript\"\n",
    "   src=\"https://utteranc.es/client.js\"\n",
    "   async=\"async\"\n",
    "   repo=\"surdarla/surdarla.github.io\"\n",
    "   issue-term=\"pathname\"\n",
    "   theme=\"github-light\"\n",
    "   label=\"ğŸ’¬ comment\"\n",
    "   crossorigin=\"anonymous\"\n",
    "/>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
