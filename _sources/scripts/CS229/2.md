# Linear Regressin & Gradient Descent

## Hypothsis function ê°€ì„¤ í•¨ìˆ˜

```{admonition} Hypothesis Definition
To Describe the supervised learining problem slightly more formally, our goal is, given a training set, to learn a function $h : X \mapsto Y$ that $h(x)$ is a "good" predictor for the corresponding value of $y$. For historical reasons, this function $h$ is called a hypothesis.
```

hypothesisë€ input(feature, x)ì™€ output(targer,label, y)ì˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í•¨ìˆ˜ë¥¼ ë§í•œë‹¤. inputì€ ë§ì´ ê³ ë ¤í• ìˆ˜ë¡ ë” ìœ ì˜ë¯¸í•œ ê°€ì„¤ì„ ë½‘ì•„ë‚¼ í™•ë¥ ì´ ë†’ì•„ì§€ê² ì§€ë§Œ, ê·¸ì— ë”°ë¼ ì§€ìˆ˜ì ìœ¼ë¡œ ì—°ì‚°ëŸ‰ì´ ëŠ˜ì–´ë‚˜ë©° ì‚¬ì‹¤ìƒ ê·¸ë ‡ê²Œ í•  ìˆ˜ ì—†ë‹¤. ë”°ë¼ì„œ ìœ ì˜ë¯¸í•´ ë³´ì´ëŠ” featureë¥¼ selectioní•˜ê³  ê·¸ê²ƒì„ ê°€ì§€ê³  ê°€ì„¤ì„ ì„¸ì›Œì•¼ í•œë‹¤. ìš°ì„ ì€ í•œ ê°œì˜ ì¢…ì†ë³€ìˆ˜(x)ì™€ í•œ ê°œì˜ ë…ë¦½ë³€ìˆ˜(y)ë¥¼ ê°€ì§€ê³  linear ì„ í˜• í•¨ìˆ˜ë¡œ ê°€ì„¤ì„ ì„¸ì›Œë³´ì.

ì˜†ì— ë³´ì´ëŠ” ê²ƒì´ ìˆ˜ì‹ ì •ì˜ì— í•„ìš”í•œ ìˆ˜í•™ì  ê¸°í˜¸ì˜ ì •ì˜ë“¤ì´ë‹¤.

````{margin}
```{glossary}
$m$
    number of training examples

$n$
    number of features

$x$
    input variable / features

$y$
    output variable / target variable

$(x,y)$
    one training example

$(x^{i},y^{i})$
    $i$-th trainig example

${\theta}_i$
    parameters, weights

$J(\theta)$
    cost function of theta(parameter)

```
````

$$
h_{\theta}(x) = \theta_{0} + \theta_{1}x
$$

ìš°ë¦¬ëŠ” ì£¼ì–´ì§„ ë°ì´í„°ë¡œ $h_{\theta}$ì™€ ì‹¤ì œ ê°€ì§€ê³  ìˆëŠ” targetê°’ì¸ $y$ì˜ ì°¨ì´ ì¦‰ $error = h_{\theta}(x) - y$ê°€ ê°€ì¥ ì‘ì€ $\theta_{0}$ì™€ $\theta_{1}$ì„ ì°¾ê³  ì‹¶ì„ ê²ƒì´ë‹¤. ì´ error,loss,cost,ì”ì°¨ ë¼ê³  í†µì¹­í•˜ëŠ” ì´ê²ƒì„ ìµœì†Œí™”í•˜ëŠ” í•¨ìˆ˜ë¥¼ cost functionì´ë¼ê³  í•œë‹¤.

## Cost function ëª©ì  í•¨ìˆ˜

ìœ„ì—ì„œ ë³´ì•˜ë“¯ì´ ìš°ë¦¬ëŠ” ê°€ì„¤í•¨ìˆ˜ $h_{\theta}(x)$ì™€ ì‹¤ì œê°’ yì™€ì˜ ë¹„ìš©(ì”ì°¨ error loss)ë¥¼ ìµœì†Œí™”í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ë¨¸ì‹ ì„ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì´ ëª©í‘œì´ë‹¤. ê²°êµ­ ì´ cost functionì— $x$ inputì„ ë„£ì—ˆì„ ë•Œ ë‚˜ì˜¤ëŠ” ê°’ $J(\theta)$ì„ ìµœì†Œí™”í•˜ëŠ” ê²ƒì´ learning algorithm(ì—¬ê¸°ì„œëŠ” supervised learning, linear regression)ì˜ ì„±ëŠ¥ì„ ë†’ì´ëŠ” ê²ƒì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤.

ê¸°ë³¸ì ì¸ cost functionì€ LSE(least squared error)ì´ë‹¤. errorì— ì œê³±ì„ í•´ì£¼ê³  ê·¸ê²ƒì˜ í•©ì„ ë”í•´ì¤˜ì„œ ìµœì†Œê°’ì„ ì°¾ëŠ” ë°©ì‹ì´ë‹¤. ì—¬ê¸°ì„œ 1/mì„ í•´ì£¼ë©´ mean squared error(MSE)ê°€ ëœë‹¤.

$$
\begin{align}
\begin{split}
J(\theta_0, \theta_1) &= \frac{1}{2m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})^2\\
&= \frac{1}{2m}\sum_{i=1}^{m}(\theta_{0} + \theta_{1}x^{(i)} - y^{(i)})^2\\
\end{split}\\
Goal = \min\limits_{\theta_{0}, \theta_{1}} J(\theta_0, \theta_1)
\end{align}
$$

```{admonition} ì™œ mì´ ì•„ë‹ˆë¼ 2mì¸ê°€?
í‰ê· ì´ë¼ë©´ {term}`m` ë°ì´í„°ì˜ ê°¯ìˆ˜ëŒ€ë¡œ ë‚˜ëˆ ì¤˜ì•¼í•˜ëŠ”ê²Œ ì•„ë‹Œê°€ í•˜ëŠ” ì˜ë¬¸ì´ ë“¤ ìˆ˜ ìˆëŠ”ë°, ë’¤ì— ë¯¸ë¶„ì„ í•˜ê²Œ ë˜ë©´ ^2ê°€ ì•ìœ¼ë¡œ íŠ€ì–´ë‚˜ì™€ 1/2ì™€ ìƒì‡„ë˜ì–´ 1ì´ ë˜ê¸° ë•Œë¬¸ì´ë‹¤. $\theta$ë¥¼ ì–´ë–¤ ìƒìˆ˜ë¡œ ë‚˜ëˆ ë„ ìƒê´€ì—†ê¸° ë•Œë¬¸ì— ê°€ëŠ¥í•˜ë‹¤.
```

ê·¸ëƒ¥ ë‹¨ìˆœí•˜ê²Œ `w = w + learning_rate * error * x` ë¥¼ ì‚¬ìš©í•´ì„œ updateí•´ê°€ë©´ì„œ thetaë“¤ì„ ì§ì ‘ ì°¾ì•„ê°€ê³  cost functionì˜ ê¸°ìš¸ê¸°ë¥¼ êµ¬í•˜ì§€ ì•Šì•„ë„ ë˜ê¸´í•œë‹¤.

## Gradient Descent ê²½ì‚¬í•˜ê°•ë²•

```{admonition} ì™œ ê²½ì‚¬í•˜ê°•ë²•ì„ ì‚¬ìš©í•˜ëŠ”ê°€?
1. ê° ë°ì´í„° ìƒ˜í”Œ í•˜ë‚˜í•˜ë‚˜ ë§ˆë‹¤ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸ë¥¼ í•´ê°€ë©° cost functionì„ ìµœì í™”í•˜ëŠ” ë°©ì‹ì€ ì‹œê°„ì´ ì˜¤ë˜ê±¸ë¦¬ê³  ë°ì´í„° ì‚¬ì´ì¦ˆê°€ ì»¤ì§€ë©´ mini-batchë¡œ ëª‡ ê°œì˜ dataset exampleë§ˆë‹¤ iterativeí•˜ê²Œ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸ í•˜ëŠ” ê²ƒì´ datasetì´ ê±°ëŒ€í•´ì§ˆ ê²½ìš°ì— ê³„ì‚°ëŸ‰ ì¸¡ë©´ì´ë‹¤ ìµœì í™” ì‹œê°„ ì¸¡ë©´ì—ì„œ ìœ ìš©í•  ìˆ˜ ìˆë‹¤.
2. closed form solutionì´ ì—†ëŠ” ê²½ìš°ì—ë„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.
3. non linearity í•¨ìˆ˜ë‚˜ ë¯¸ë¶„ê³„ìˆ˜ì™€ ê·¼ì„ ê³„ì‚°í•˜ê¸° ì–´ë ¤ìš´ ê²½ìš°ì—ë„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.
```

Gradient Descent ê²½ì‚¬í•˜ê°•ë²•ì€ 1ì°¨ ë¯¸ë¶„ê³„ìˆ˜ë¥¼ ì´ìš©í•´ í•¨ìˆ˜ì˜ ìµœì†Œê°’ì„ ì°¾ì•„ë‚´ëŠ” iterativeí•œ ë°©ë²•ì´ë‹¤. Steepest Descentë¼ê³ ë„ ë¶ˆë¦°ë‹¤. ì•ì´ í•˜ë‚˜ë„ ì•ˆë³´ì´ê³  ì–´ë””ê°€ ìœ„ì´ê³  ì–´ë””ê°€ ì•„ë˜ì¸ì§€ë§Œ ë³´ì´ëŠ” ìƒí™©ì—ì„œ í•œ ë°œì”© ì•„ë˜ë¡œ ë‚´ë ¤ê°€ëŠ” ê²ƒê³¼ ë¹„ìŠ·í•˜ê¸° ë•Œë¬¸ì´ë‹¤. í•˜ì‚°ì˜ ëª©í‘œê°€ ì‚°ì˜ ë§¨ ë°‘ì´ë“¯ cost functionì˜ ìµœì†Œê°’ì„ ì°¾ëŠ” ê²ƒì´ ëª©í‘œì´ê³ , cost functionì˜ ìµœì†Œê°’ì˜ ì§€ì ì€ ê³§ hypothesis functionì˜ íŒŒë¼ë¯¸í„° $\theta$ì˜ ìµœì ê°’ì´ ëœë‹¤.

```{prf:algorithm} Gradient Descent Algorithm
- start with some ${\theta}_0$, ${\theta}_1$
- keep changing ${\theta}_0$, ${\theta}_1$ to reduce $J({\theta}_0, {\theta}_1)$ until we hopefully end up at a minimum

repeat until convergence{\
    ${\theta}_j := {\theta}_j - {\alpha}{\frac \partial {\partial{\theta}_j} } J({\theta}_0, {\theta}_1)\space\text {for j=0,j=1}$ \
}
```

ìœ„ì˜ gradient descent ì•Œê³ ë¦¬ì¦˜ì„ ìš°ë¦¬ì˜ cost functionì— ì ìš©í•´ë³´ì.

$$
\frac \partial {\partial{\theta}_j} J({\theta}_0, {\theta}_1) = \frac \partial {\partial{\theta}_j} \bigg[\frac{1}{2m}\sum_{i=1}^{m}(\theta_{0} + \theta_{1}x^{(i)} - y^{(i)})^2\bigg]
$$
$$
j = 0 : \frac \partial {\partial{\theta}_0} J({\theta}_0, {\theta}_1) = \frac{1}{m}\sum_{i=1}^{m}(\theta_{0} + \theta_{1}x^{(i)} - y^{(i)})
$$
$$
j = 1 : \frac \partial {\partial{\theta}_1} J({\theta}_0, {\theta}_1) = \frac{1}{m}\sum_{i=1}^{m}(\theta_{0} + \theta_{1}x^{(i)} - y^{(i)})x^{(i)}
$$

ë‹¤ì‹œ í‘œí˜„í•˜ë©´

$$
{\theta}_0 := {\theta}_0 - {\alpha}\frac 1 m\sum_{i=1}^{m}(h_\theta(x^i) - y^i)
$$
$$
{\theta}_1 := {\theta}_1 - {\alpha}\frac 1 m\sum_{i=1}^{m}(h_\theta(x^i) - y^i)x^i\\
$$


```{raw} html
<script
   type="text/javascript"
   src="https://utteranc.es/client.js"
   async="async"
   repo="surdarla/surdarla.github.io"
   issue-term="pathname"
   theme="github-light"
   label="ğŸ’¬ comment"
   crossorigin="anonymous"
/>
```
