# Linear Regressin & Gradient Descent

## Hypothsis function 가설 함수

```{admonition} Hypothesis Definition
To Describe the supervised learining problem slightly more formally, our goal is, given a training set, to learn a function $h : X \mapsto Y$ that $h(x)$ is a "good" predictor for the corresponding value of $y$. For historical reasons, this function $h$ is called a hypothesis.
```

hypothesis란 input(feature, x)와 output(targer,label, y)의 관계를 나타내는 함수를 말한다. input은 많이 고려할수록 더 유의미한 가설을 뽑아낼 확률이 높아지겠지만, 그에 따라 지수적으로 연산량이 늘어나며 사실상 그렇게 할 수 없다. 따라서 유의미해 보이는 feature를 selection하고 그것을 가지고 가설을 세워야 한다. 우선은 한 개의 종속변수(x)와 한 개의 독립변수(y)를 가지고 linear 선형 함수로 가설을 세워보자.

옆에 보이는 것이 수식 정의에 필요한 수학적 기호의 정의들이다.

````{margin}
```{glossary}
$m$
    number of training examples   

$n$
    number of features   

$x$
    input variable / features   

$y$
    output variable / target variable   

$(x,y)$
    one training example   

$(x^{i},y^{i})$
    $i$-th trainig example   

${\theta}_i$
    parameters, weights

$J(\theta)$
    cost function of theta(parameter)
    
```
````

$$
h_{\theta}(x) = \theta_{0} + \theta_{1}x
$$

우리는 주어진 데이터로 $h_{\theta}$와 실제 가지고 있는 target값인 $y$의 차이 즉 $error = h_{\theta}(x) - y$가 가장 작은 $\theta_{0}$와 $\theta_{1}$을 찾고 싶을 것이다. 이 error,loss,cost,잔차 라고 통칭하는 이것을 최소화하는 함수를 cost function이라고 한다.

## Cost function 목적 함수

위에서 보았듯이 우리는 가설함수 $h_{\theta}(x)$와 실제값 y와의 비용(잔차 error loss)를 최소화하는 방법으로 머신을 학습시키는 것이 목표이다. 결국 이 cost function에 $x$ input을 넣었을 때 나오는 값 $J(\theta)$을 최소화하는 것이 learning algorithm(여기서는 supervised learning, linear regression)의 성능을 높이는 것이라고 볼 수 있다.

기본적인 cost function은 LSE(least squared error)이다. error에 제곱을 해주고 그것의 합을 더해줘서 최소값을 찾는 방식이다. 여기서 1/m을 해주면 mean squared error(MSE)가 된다.

$$J(\theta_0, \theta_1) = \frac{1}{2m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})^2 = \frac{1}{2m}\sum_{i=1}^{m}(\theta_{0} + \theta_{1}x^{(i)} - y^{(i)})^2 $$
$$Goal = \min\limits_{\theta_{0}, \theta_{1}} J(\theta_0, \theta_1)$$

```{admonition} 왜 m이 아니라 2m인가?
평균이라면 {term}`m` 데이터의 갯수대로 나눠줘야하는게 아닌가 하는 의문이 들 수 있는데, 뒤에 미분을 하게 되면 ^2가 앞으로 튀어나와 1/2와 상쇄되어 1이 되기 때문이다. $\theta$를 어떤 상수로 나눠도 상관없기 때문에 가능하다.
```

그냥 단순하게 w = w + learning_rate * error * x 를 사용해서 update해가면서 theta들을 직접 찾아가고 cost function의 기울기를 구하기 않아도 되긴한다. 하지만 각 데이터 샘플 하나하나 마다 파라미터를 업데이트를 해가며 cost function을 최적화하는 방식으로 시간이 오래걸리고 데이터 사이즈가 커지면 mini-batch로 몇 개마다 파라미터를 업데이트 하는 것이 

## Gradient Descent 경사하강법



```{prf:algorithm} Ford–Fulkerson

**Inputs** Given a Network $G=(V,E)$ with flow capacity $c$, a source node $s$, and a sink node $t$

**Output** Compute a flow $f$ from $s$ to $t$ of maximum value

1. $f(u, v) \leftarrow 0$ for all edges $(u,v)$
2. While there is a path $p$ from $s$ to $t$ in $G_{f}$ such that $c_{f}(u,v)>0$
	for all edges $(u,v) \in p$:

	1. Find $c_{f}(p)= \min \{c_{f}(u,v):(u,v)\in p\}$
	2. For each edge $(u,v) \in p$

		1. $f(u,v) \leftarrow f(u,v) + c_{f}(p)$ *(Send flow along the path)*
		2. $f(u,v) \leftarrow f(u,v) - c_{f}(p)$ *(The flow might be "returned" later)*
```